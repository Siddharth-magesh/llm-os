====================================
  LLM-OS Quick Start Guide
====================================

LAUNCH:
====================================

Start LLM-OS:
  launch.bat

This launches with Ollama by default (local, private).
To use Groq instead (cloud, fast), see CHANGING PROVIDER below.

====================================
VERIFY INSTALLATION:
====================================

Run tests:
  tests\run_tests.bat

Quick check:
  verify.bat

====================================
CHANGING PROVIDER:
====================================

Option 1 - Command Line (Temporary):
  python -m llm_os --provider groq
  python -m llm_os --provider ollama

Option 2 - Edit Default (Permanent):
  File: src\llm_os\core.py
  Line 82: default_provider: str = "ollama"

  Change to: default_provider: str = "groq"

====================================
PROVIDERS:
====================================

Groq (Cloud):
  - Model: llama-3.3-70b-versatile
  - Speed: ~100-200ms latency
  - Status: WORKING ✓

Ollama (Local):
  - Model: llama3.2:3b
  - Speed: Depends on hardware
  - Status: Available (if installed)

====================================
FEATURES:
====================================

✓ 14 Filesystem MCP tools
✓ Tool calling (no hallucination)
✓ Read/write/list files
✓ Directory operations
✓ File search
✓ Provider selection

====================================
USAGE:
====================================

Commands:
  "list all files"
  "read QUICK_START.txt"
  "create a folder called test"
  "search for .py files"

CLI options:
  --provider groq     Use Groq
  --provider ollama   Use Ollama
  --no-ui             CLI mode (no TUI)
  -c "command"        Single command

====================================
FILES:
====================================

launch.bat          Main launcher
verify.bat          Quick test
tests/integration/  Test scripts

====================================
