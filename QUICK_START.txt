====================================
  LLM-OS Quick Start Guide
====================================

LAUNCH:
====================================

Start LLM-OS:
  launch.bat

This launches with Ollama by default (local, private).
To use Groq instead (cloud, fast), see CHANGING PROVIDER below.

====================================
VERIFY INSTALLATION:
====================================

Run tests:
  tests\run_tests.bat

Quick check:
  verify.bat

====================================
CHANGING PROVIDER:
====================================

Option 1 - TUI Command (Live):
  Launch TUI, then type:
  /provider groq
  /provider ollama

Option 2 - Command Line (Session):
  python -m llm_os --provider groq
  python -m llm_os --provider ollama

Option 3 - Edit .env (Permanent):
  File: .env
  Change: LLM_OS_PROVIDER=groq
  or:     LLM_OS_PROVIDER=ollama

====================================
PROVIDERS:
====================================

Groq (Cloud):
  - Model: llama-3.3-70b-versatile
  - Speed: ~100-200ms latency
  - Status: WORKING ✓

Ollama (Local):
  - Model: llama3.2:3b
  - Speed: Depends on hardware
  - Status: Available (if installed)

====================================
FEATURES:
====================================

✓ 14 Filesystem MCP tools
✓ Tool calling (no hallucination)
✓ Read/write/list files
✓ Directory operations
✓ File search
✓ Provider selection
✓ CLI Bypass (execute shell commands)
✓ Dynamic configuration (TUI commands)
✓ Modular config system (.env support)

====================================
USAGE:
====================================

Natural Language Commands:
  "list all files"
  "read QUICK_START.txt"
  "create a folder called test"
  "search for .py files"

CLI Bypass (! prefix):
  !dir                List files (Windows)
  !ls -la             List files (Linux)
  !git status         Check git status
  !python --version   Check Python version

TUI Commands:
  /help               Show help
  /config             Show configuration
  /provider groq      Switch to Groq
  /provider ollama    Switch to Ollama
  /model <name>       Switch model
  /clear              Clear screen
  /quit               Exit

CLI options:
  --provider groq     Use Groq
  --provider ollama   Use Ollama
  --no-ui             CLI mode (no TUI)
  -c "command"        Single command

====================================
CONFIGURATION:
====================================

Configuration files:
  .env                    API keys and secrets
  config/                 Modular configuration
    llm_config.py         Base LLM config
    mcp_config.py         MCP server config
    security_config.py    Security settings
    ui_config.py          UI preferences
    providers/
      groq.py             Groq provider config
      ollama.py           Ollama provider config

Environment variables (.env):
  GROQ_API_KEY          Your Groq API key
  OLLAMA_BASE_URL       Ollama server URL
  LLM_OS_PROVIDER       Default provider

====================================
FILES:
====================================

launch.bat          Main launcher
verify.bat          Quick test
tests/integration/  Integration tests
tests/cli/          CLI bypass tests
tests/config/       Configuration tests

====================================
